{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bernardo Tinti_Mnist_LenNet.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MxTEFfTcinN"
      },
      "source": [
        "#Codigo Criado por Luiz Eduardo Soares Emidio da Silva durante o desenvolvimento de um PIBIC \n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "from keras import regularizers\n",
        "from keras.models import Model\n",
        "\n",
        "from keras import backend as K \n",
        "K.set_learning_phase(1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as sty\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "import os\n",
        "import random as rn\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlfoYfcNqnGZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5T4-_oJdA79"
      },
      "source": [
        "#Configurações Arbritarias escolhidas para treinamento\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "#Cada imagem do MNIST tem o tamanho de 28 por 28 pixels\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa75EfEL0zBO"
      },
      "source": [
        "#Carregando imagens e plotando alguns exemplos \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        " \n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train  /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# plot first 36 images in MNIST\n",
        "fig, ax = plt.subplots(6, 6, figsize = (12, 12))\n",
        "fig.suptitle('First 36 images in MNIST')\n",
        "fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "for x, y in [(i, j) for i in range(6) for j in range(6)]:\n",
        "    ax[x, y].imshow(x_train[x + y * 6].reshape((28, 28)), cmap = 'gray')\n",
        "#    ax[x, y].set_title(y_train[x + y * 6])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS3Ei14Q01-8"
      },
      "source": [
        "#Inserir estrutura da CNN nessa parte do codigo\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(28, (3,3), padding='same', kernel_regularizer=regularizers.l2(1e-4), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(28, (3,3), padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# -===========================================================================-\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(1e-4), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# -===========================================================================-\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(1e-4), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512,activation ='relu'))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW2m-zA9dI8S"
      },
      "source": [
        "# Compilar a CNN\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo0MEMos1ApL"
      },
      "source": [
        "# Imprimir a topologia\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY0HRy_t1Jua"
      },
      "source": [
        "# Treinar a CNN\n",
        "\n",
        "es=EarlyStopping(monitor='vai_loss', mode='min', verbose=1)\n",
        "results=model.fit(x_train, y_train, \n",
        "                  batch_size=batch_size,\n",
        "                  epochs=epochs,\n",
        "                  verbose=1,\n",
        "                  validation_split=0.2,\n",
        "                  callbacks=[es]\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZTfq2eq1M4K"
      },
      "source": [
        "# Executar a avaliação (teste)\n",
        "\n",
        "score=model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: ', score[0])\n",
        "print('Test accuracy: ', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efplgnzS1PNB"
      },
      "source": [
        "# Plota o grafico do histórico de evolução da taxa de acertos da rede\n",
        "\n",
        "sty.use('seaborn-whitegrid')\n",
        "plt.plot(results.history['accuracy'],'k--')\n",
        "plt.plot(results.history['val_accuracy'],'k')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Plota o grafico do histórico de evolução da taxa de perda da rede \n",
        "\n",
        "plt.plot(results.history['loss'],'k--')\n",
        "\n",
        "plt.plot(results.history['val_loss'],'k')\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laG1nF5x1Xyq"
      },
      "source": [
        "\n",
        "# Preparar Matriz de Confusão\n",
        "\n",
        "y_predict=np.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "# Preparar Matriz de Confusão\n",
        "\n",
        "cm=confusion_matrix(np.argmax(y_test, axis=1), y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDb9J1lA1ayQ"
      },
      "source": [
        "# Plotar a matrix de confusão \n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "  plt.imshow(cm, interpolation = 'nearest',cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation = 45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  \n",
        "  if normalize:\n",
        "    cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
        "    print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "    print(\"Confusion matrix, without normalization\")\n",
        "  \n",
        "  print(cm)\n",
        "  \n",
        "  thresh = cm.max()/2\n",
        "  for i, j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i,j], horizontalalignment=\"center\", color=\"white\" if cm[i,j]>thresh else \"black\")\n",
        "   \n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRXFqMwAdNHJ"
      },
      "source": [
        "# Chamada da matrix de confuzão \n",
        "\n",
        "cm_plot_labels = ['0','1','2','3','4','5','6','7','8','9']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Consioin Matrix')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7miqVRNXGvH"
      },
      "source": [
        "# Salvando o modelo, a arquitetura da CNN\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"cnn.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "# Salvando os pessos da CNN\n",
        "\n",
        "model.save_weights(\"cnn_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDhSRNiSdYxR"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# Carregando o modelo\n",
        "json_file=open(\"cnn.json\", \"r\")\n",
        "cnn_json=json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "cnn_model=model_from_json(cnn_json)\n",
        "\n",
        "# Carregando os pesos\n",
        "\n",
        "cnn_model.load_weights(\"cnn_weights.h5\")\n",
        "\n",
        "# Predição usando o modelo carregando\n",
        "y_predict=np.argmax(cnn_model.predict(x_test), axis=1)\n",
        "\n",
        "print(y_predict)\n",
        "y=np.argmax(y_test, axis=1)\n",
        "print(y)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(x_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlDZXqijeptq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}