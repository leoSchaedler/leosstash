{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# **Recurrent Neural Network for Weather Forecasting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rZnJaGTWQw0"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TokBlnUhWFw9"
      },
      "source": [
        "**Dataset - Dados Climáticos [[link]](https://www.bgc-jena.mpg.de/wetter/)**\n",
        "* 14 caracteristicas (temp, pressão, umididade, etc). \n",
        "\n",
        "* Granularidade: 10 minutos desde 2003\n",
        "\n",
        "* Utilizaremos a fração de 2009 até 2016. (Processada por François Chollet [[link]](https://www.manning.com/books/deep-learning-with-python))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyv_i85IWInT"
      },
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX6uGeeeWIkG"
      },
      "source": [
        "df = pd.read_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdbOWXiTWM2T"
      },
      "source": [
        "Visualização dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojHE-iCCWIhz"
      },
      "source": [
        "df.head(-200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfbpcV0MWQzl"
      },
      "source": [
        "*  **Objetivo**: determinar uma temperatura no futuro (*target*). Para tal, aprenderemos o padrão da variação no histórico (*history*)\n",
        "\n",
        "* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoFJZmXBaxCc"
      },
      "source": [
        "As variáveis abaixo garantem padronização e reprodutibilidade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia-MPAHxbInX"
      },
      "source": [
        "TRAIN_SPLIT = 300000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x-GgENynHdx"
      },
      "source": [
        "tf.random.set_seed(13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YEwr-NoWUpV"
      },
      "source": [
        "## Part 1: Previsão univalorada\n",
        "Primeiro vamos criar um modelo utilizando apenas uma *feature* (temperatura). Abaixo extraimos apenas a informação de temperatura do dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbdcnm1_WIY9"
      },
      "source": [
        "data = df['T (degC)']\n",
        "\n",
        "data.index = df['Date Time']\n",
        "\n",
        "print (\"Numero de Amostras: \", len(data))\n",
        "print (\"Vetor de valores:\" , data.values)\n",
        "data.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQB-46MyWZMm"
      },
      "source": [
        "Abaixo plotamos o gráfico de variação da temperatura desde 2009 a 2016"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftOExwAqWXSU"
      },
      "source": [
        "data.plot(subplots=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQSbi-PiA9U4"
      },
      "source": [
        "Recuperando apenas os valores e normalizando os dados\n",
        "* Importante (Apenas utilizando os dados de treinamento)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejSEiDqBWXQa"
      },
      "source": [
        "uni_data = data.values\n",
        "print (\"Dados: \", uni_data)\n",
        "uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\n",
        "print (\"Média: \", uni_train_mean)\n",
        "uni_train_std = uni_data[:TRAIN_SPLIT].std()\n",
        "print (\"Desv. Padrão: \", uni_train_std)\n",
        "uni_data = (uni_data-uni_train_mean)/uni_train_std\n",
        "print (\"Dados Norm: \", uni_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn8A_nrccKtn"
      },
      "source": [
        "**Criação dos Datasets de Treinamento e Validação**'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz3qJ7VrSOCp"
      },
      "source": [
        "* A função abaixo retorna a fração do dataset a ser utilizada sendo:\n",
        "\n",
        "          * history_size: janela a ser observada\n",
        "          * target_size: O exato momento a ser avaliado \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRamgBs1R2Os"
      },
      "source": [
        "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i)\n",
        "    if i < 1000: print(indices)\n",
        "    # Reshape data from (history_size,) to (history_size, 1)\n",
        "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
        "    labels.append(dataset[i+target_size])\n",
        "  return np.array(data), np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo para a base de treinamento: univariate_data(dataset, 0, 300000, 50, 5), considerando janela histórica de tamanho 50 e rótulo 5 observações a frente.\n",
        "\n",
        "start_index = 0\n",
        "\n",
        "end_index = 300000\n",
        "\n",
        "history_size = 50\n",
        "\n",
        "target_size = 5\n",
        "\n",
        "dataset = [t0, t1, ...., t300000]\n",
        "\n",
        "treino = [[t0, .., t49],[t54], [t1, .., t50],[t55], [t2, .., t51],[t56] ...]\n",
        "\n",
        "shape do treino = 299950 sequências de tamanho (50) + rótulo tamanho (1)\n"
      ],
      "metadata": {
        "id": "7i7vD8-TnfXF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v6UAkSdppXnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LuxdxpDdbft7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJJ-T49vWXOZ"
      },
      "source": [
        "'''Tamanho da Janela do Historico'''\n",
        "univariate_past_history = 50  #50 observacoes anteriores\n",
        "future = univariate_future_target = 5  # prever 5 observações a frente \n",
        "\n",
        "x_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
        "                                           univariate_past_history,\n",
        "                                           univariate_future_target)\n",
        "x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None,\n",
        "                                       univariate_past_history,\n",
        "                                       univariate_future_target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_uni.shape)"
      ],
      "metadata": {
        "id": "mCzmPKB_mwPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UO1n3yNDmse_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hni3Jt9OMR1_"
      },
      "source": [
        "Para efeito de visualização, vamos analisar as janelas de observações criadas e sua respectiva temperatura (label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVukM9dRipop"
      },
      "source": [
        "def create_time_steps(length):\n",
        "  time_steps = []\n",
        "  for i in range(-length, 0, 1):\n",
        "    time_steps.append(i)\n",
        "  return time_steps\n",
        "\n",
        "def show_plot(plot_data, delta, title):\n",
        "    labels = ['History', 'True Future', 'Model Prediction']\n",
        "    marker = ['.-', 'gX', 'ro']\n",
        "    time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "    if delta:\n",
        "      future = delta\n",
        "    else:\n",
        "      future = 0\n",
        "\n",
        "    plt.title(title)\n",
        "    for i, x in enumerate(plot_data):\n",
        "      if i:\n",
        "        plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "                label=labels[i])\n",
        "      else:\n",
        "        plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "    plt.legend()\n",
        "    plt.xlim([time_steps[0], (future+5)*2])\n",
        "    plt.xlabel('Time-Step')\n",
        "    return plt\n",
        "\n",
        "sample_id = 400\n",
        "print(\"#Amostras:\", len(x_train_uni),\"#Labels: \", len(y_train_uni))\n",
        "print (\"Amostra[0]:\\n\", x_train_uni[sample_id],\"\\nTemperatura: \", y_train_uni[sample_id])\n",
        "show_plot([x_train_uni[sample_id], y_train_uni[sample_id]], future, 'Sample Example')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5rUJ_2YMWzG"
      },
      "source": [
        "### Baseline\n",
        "Para efeitos comparativos, vamos criar um modelo de predição utilizando a média das últimas 20 observações. Este simples modelo nos revela como a média pode ser falha para prever séries temporais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9nYWcxMMWnr"
      },
      "source": [
        "def baseline(history):\n",
        "  return np.mean(history)\n",
        "\n",
        "show_plot([x_train_uni[sample_id], y_train_uni[sample_id], baseline(x_train_uni[sample_id])], 0,\n",
        "           'Baseline Prediction Example')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "### Recurrent neural network (SimpleRNN and LSTM)\n",
        "\n",
        "Definindo os datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk-evkrmMWh9"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
        "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
        "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2AmKkyVS5Ht"
      },
      "source": [
        "The following visualisation should help you understand how the data is represented after batching.\n",
        "\n",
        "![Time Series](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/time_series.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nagdTRNfPuZ"
      },
      "source": [
        "##Criando as arquiteturas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFaqK9e0RF1M"
      },
      "source": [
        "RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAHki0m9Q-72"
      },
      "source": [
        "print(x_train_uni.shape[1])\n",
        "print(x_train_uni.shape[2])\n",
        "simple_rnn_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(16, return_sequences=True, input_shape=(x_train_uni.shape[1], x_train_uni.shape[2])),    \n",
        "    tf.keras.layers.SimpleRNN(8),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "simple_rnn_model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "simple_rnn_model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_28S_NnQ-Z4"
      },
      "source": [
        "LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDbpHosCMWZO"
      },
      "source": [
        "\n",
        "simple_lstm_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(16, return_sequences=True, input_shape=(x_train_uni.shape[1], x_train_uni.shape[2])),\n",
        "    tf.keras.layers.LSTM(8),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "simple_lstm_model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "\n",
        "simple_lstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euyPo_lyNryZ"
      },
      "source": [
        "## Treinamento\n",
        "\n",
        "Cada epoca conterá apenas 200 steps (lotes) ao invés da base toda. Podemos alterar este número depois para ver o impacto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5isdRf_5I2y6"
      },
      "source": [
        "EVALUATION_INTERVAL = 200\n",
        "EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYSvlKbLQ4X_"
      },
      "source": [
        "RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4WxBSnCo-i-"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es=EarlyStopping(monitor='val_loss', verbose=1, patience=3)\n",
        "rnn_log = simple_rnn_model.fit(train_univariate, epochs=EPOCHS,\n",
        "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                      validation_data=val_univariate, validation_steps=50, callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gD-W86jQ5dF"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NzLbuHxI3BP"
      },
      "source": [
        "\n",
        "lstm_log = simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n",
        "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                      validation_data=val_univariate, validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRG9inwlQmF5"
      },
      "source": [
        "##Visualização do Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP_xBAW3sbp5"
      },
      "source": [
        "simple_lstm_model.save('model')\n",
        "\n",
        "jsmodel=simple_lstm_model.to_json()\n",
        "with open('model_config.json', 'w') as json_file:\n",
        "    json_file.write(jsmodel)\n",
        "\n",
        "def plot_train_history(history, title):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpGVZS1XtBBk"
      },
      "source": [
        " plot_train_history(rnn_log,\n",
        "                   'RNN Training and validation loss')\n",
        " plot_train_history(lstm_log,\n",
        "                   'LSTM Training and validation loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYLS69gdURgM"
      },
      "source": [
        "def plot_preds(plot_data, delta=0):\n",
        "    labels = ['History', 'True Future', 'RNN Prediction','LSTM Prediction']\n",
        "    marker = ['.-', 'gX', 'ro' , 'bo']\n",
        "    time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "    \n",
        "\n",
        "    future = delta\n",
        "\n",
        "    plt.title('Predictions')\n",
        "    for i, x in enumerate(plot_data):\n",
        "      if i:\n",
        "        plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "                label=labels[i])\n",
        "      else:\n",
        "        plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "    plt.legend()\n",
        "    plt.xlim([time_steps[0], (future+5)*2])\n",
        "    plt.xlabel('Time-Step')\n",
        "    return plt\n",
        "\n",
        "for x, y in val_univariate.take(5):\n",
        "  plot = plot_preds([x[0].numpy(), y[0].numpy(),\n",
        "                    simple_rnn_model.predict(x)[2], simple_lstm_model.predict(x)[0]], future)\n",
        "  plot.show()\n",
        "\n",
        "print(simple_rnn_model.predict(x)[0])\n",
        "print(val_univariate.take(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHzyM4eLnj2K"
      },
      "source": [
        "#TODO Calcule do erro\n",
        "\n",
        "err_rnn=0\n",
        "err_lstm=0\n",
        "\n",
        "for x, y in val_univariate.take(100):\n",
        "  err_rnn += abs(y[0].numpy() - simple_rnn_model.predict(x)[0])\n",
        "  err_lstm += abs(y[0].numpy() - simple_lstm_model.predict(x)[0])\n",
        "  \n",
        "err_rnn = err_rnn/100\n",
        "err_lstm = err_lstm/100\n",
        "  \n",
        "print(err_rnn, err_lstm)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOzaIRYBhqwg"
      },
      "source": [
        "#Exercícios\n",
        "\n",
        "Para o melhor entendimento, algumas questões devem ser avaliadas!\n",
        "\n",
        "* Se treinar por mais épocas e mais instâncias, aumenta a performance da rede? \n",
        "\n",
        "* A rede se comporta melhor para prever 1, 3, 5 ou 10 observações à frente?\n",
        "\n",
        "* Se alterar o tamanho da janela de histórico, qual deve ser impacto? \n",
        "\n",
        "* Calcule uma taxa de acerto (use todas amostras de validação)\n",
        "\n",
        "Existe alguma relação entre o tamanho da janela de histórico com o número de dias que desejamos prever a frente?\n",
        "\n",
        "Na sua opinião, a temperatura por si só, é eficiente como único dado para sua própria predição? (Data Representation)\n"
      ]
    }
  ]
}