{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-bfht2Sp04O"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction (Deep Features)\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "from skimage import feature\n",
        "from skimage.feature import hog\n",
        "from imutils import paths\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Load Inception_v3 pretrained on ImageNet dataset\n",
        "W=224\n",
        "H=224\n",
        "#model = InceptionV3(include_top=False, weights='imagenet', pooling='avg', input_tensor=Input(shape=(W,H,3)))\n",
        "model = MobileNetV2(include_top=False, weights='imagenet', pooling='avg', input_tensor=Input(shape=(W,H,3)))\n",
        "#model = ResNet50(include_top=False, weights='imagenet', pooling='avg', input_tensor=Input(shape=(W,H,3)))\n",
        "#model = Xception(include_top=False, weights='imagenet', pooling='avg')\n",
        "#\n",
        "# List of paths\n",
        "import os\n",
        "file_list=[]\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/humanos\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/praia\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/obras\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/onibus\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/dino\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/elefante\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/flores\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/cavalos\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/montanhas\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/comida\"))\n",
        "\n",
        "# general path\n",
        "path='/content/drive/My Drive/Base1/'\n",
        "\n",
        "W=224\n",
        "H=224\n",
        "\n",
        "# list of classes\n",
        "class_names=['humanos', 'praia', 'obras', 'onibus', 'dino', 'elefante', 'flores', 'cavalos', 'montanhas', 'comida']\n",
        "\n",
        "\n",
        "X_deep = []\n",
        "y = []\n",
        "\n",
        "# Gera lista com as imagens\n",
        "for classes_files, classe in zip (file_list, range(2)):\n",
        "    for i in range(len(classes_files)):\n",
        "      name= str(path) + str(class_names[classe]) + str('/') + str(classes_files[i])\n",
        "#      print(name)\n",
        "      y.append(classe)\n",
        "\n",
        "# Carrega a imagem, pré-processa e inclui em uma lista\n",
        "      imagem = cv2.imread(name)\n",
        "      img = cv2.resize(imagem,(W,H))\n",
        "      xd = image.img_to_array(img)\n",
        "      xd = np.expand_dims(xd, axis=0)\n",
        "      xd = preprocess_input(xd)\n",
        "      X_deep.append(xd)\n",
        "\n",
        "# Extrai características usando o modelo profundo pré-treinado (deep learning)\n",
        "X_deep = np.asarray(X_deep)\n",
        "X_deep = X_deep.reshape(X_deep.shape[0], W, H, 3)\n",
        "X =  model.predict(X_deep)\n",
        "\n",
        "# Salva as características extraídas em um csv (um vetor de valores para cada imagem)\n",
        "df = pd.DataFrame(X)\n",
        "df.to_csv('X_im.csv', header=False, index=False)\n",
        "\n",
        "# Salva y que contém a classe de cada imagem\n",
        "df_class = pd.DataFrame(y)\n",
        "df_class.to_csv('y_im.csv', header=False, index=False)"
      ],
      "metadata": {
        "id": "DsoZD004OfRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de como carregar os arquivos gerados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Labels\n",
        "y = pd.read_csv('y_im.csv', header=None)\n",
        "y=y.to_numpy()\n",
        "y=np.ravel(y)\n",
        "print(y.shape)\n",
        "\n",
        "# deep features\n",
        "X = pd.read_csv('X_im.csv', header=None)\n",
        "X=X.to_numpy()\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "S5rl3X6iTAb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "# Definição dos parâmetros a serem avaliados\n",
        "parameters_MLP=[{'hidden_layer_sizes':[500, (500,200)],\n",
        "             'activation':['relu', 'logistic'],}]\n",
        "\n",
        "parameters_SVM = [\n",
        "  {'C': [1, 5, 10, 50],\n",
        "   'gamma': [0.1, 0.01, 0.001, 0.0001, 'scale'],\n",
        "   'kernel': ['rbf', 'poly', 'linear']},\n",
        "]\n",
        "\n",
        "# Separar uma parte dos dados para validação\n",
        "X, X_val, y, y_val=train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
        "\n",
        "# definição da técnica a ser utilizada\n",
        "clf=MLPClassifier(random_state=46, max_iter=500)\n",
        "#clf=SVC(probability=True)\n",
        "\n",
        "gs=GridSearchCV(clf, parameters_MLP, cv=3)\n",
        "gs.fit(X_val, y_val)\n",
        "clf=gs.best_estimator_\n",
        "print(\"Melhores parâmetros:\", gs.best_params_)\n",
        "\n",
        "from tabulate import tabulate\n",
        "df=gs.cv_results_\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))\n",
        "\n",
        "result=model_selection.cross_val_score(clf, X, y, cv=5)\n",
        "print(\"Accuracy: %.5f\" % result.mean())\n",
        "print(\"std: %.5f\" % result.std())\n",
        "y_pred=model_selection.cross_val_predict(clf, X, y, cv=5)\n",
        "ma=confusion_matrix(y, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(ma)"
      ],
      "metadata": {
        "id": "RoYOqTQqPiH9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}