{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema\n",
    "Implementar um algoritmo de detecção de anomalias e aplicá-lo para detectar falhas em servidores em uma rede.<br>\n",
    "Usar um modelo baseado na Gaussiana Multivariada para detectar observações anômalos.<br>\n",
    "O exercício é dividido em duas partes:\n",
    "* Parte 1: Ajustar a distribuição Gaussiana Multivariada para um dataset com duas variáveis (bidimensional)\n",
    "* Parte 2: Aplicar o algoritmo de detecção de anomalia para um dataset com maior número de dimensões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1 - Dataset bidimensional\n",
    "* Passo 1 - Carregar dados\n",
    "* Passo 2 - Visualizar dados de treinamento\n",
    "* Passo 3 - Treinaar o modelo\n",
    "* Passo 4 - Verificar aderência do modelo\n",
    "* Passo 5 - Ajustar o modelo\n",
    "* Passo 6 - Visualizar as anomalias no conjunto de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1 - Carregar dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar dois arquivos, o primero com dados de treinamento e o segundo com dados de validação.<br>\n",
    "* Os dados de treinamento consistem de 307 observaçoes de latência e throughput do servidor, as duas características (features) que serão usadas no treinamento não supervisionado, e serão carregados na matriz Xtre, com os dados de latência na coluna 1 e de throughput na coluna 2.<br>\n",
    "* Os dados de validação consistem consistem de 307 observações rotuladas. Os valores das caracteristicas são carregados na matriz Xval eos rátulos na matriz Yval<br>\n",
    "* Assume-se que os dados possuem distribuição normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo com dados de treinamento\n",
    "Xtre = np.loadtxt('DadosTreinamento1.csv', delimiter=',')\n",
    "print(np.shape(Xtre))\n",
    "\n",
    "# Array com dados de latência\n",
    "latencia = Xtre[:,0]\n",
    "# Array com dados de throughput\n",
    "throughput = Xtre[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo com dados de validação\n",
    "XYval = np.loadtxt('DadosValidacao1.csv', delimiter=',')\n",
    "Xval = XYval[:,[0,1]]\n",
    "Yval = XYval[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 2 - Visualizar dados de treinamento\n",
    "Cosntruir o histograma dos dados de latência e troughput.\n",
    "Plotar o diagrama de dispersão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histrograma dos dados de latência\n",
    "plt.hist(latencia,50,facecolor='blue')\n",
    "plt.title(\"Histograma dos dados de latência\")\n",
    "plt.show()\n",
    "\n",
    "# Histrograma dos dados de troughput\n",
    "plt.hist(throughput,50,facecolor='blue')\n",
    "plt.title(\"Histograma dos dados de throughput\")\n",
    "plt.show()\n",
    "\n",
    "# Diagrama de dispersão dos dados de treinamento\n",
    "plt.scatter(latencia,throughput, s=3)\n",
    "plt.xlabel('Latência (ms)')\n",
    "plt.ylabel('Throughput (mb/s)')\n",
    "plt.title(\"Dispersão dos dados de treinamento\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 3 - Treinar o modelo\n",
    "A fase de treinamento do algoritmo consiste basicamente no cálculo dos parâmetros da distribuição Gaussiana multivariada. A distribuição será utilizada para classificar novos dados como anomalia ou não. Na Parte 1 estamos utilizando a Gaussiana Bivariada como modelo (apenas duas variáveis), mas o algoritmo precisa ser matricial para que possa usado com mais variáveis.<br><br>\n",
    "O treinamento consiste em calcular o vetor de médias e a matriz de covariância.<br><br>\n",
    "\n",
    "Se o seu código estiver correto você deve encontrar os seguintes valores:\n",
    "* Vetor de médias:<br>\n",
    "$\\begin{bmatrix}\n",
    "14.11222578 & 14.99771051\n",
    "\\end{bmatrix}$<br><br>\n",
    "* Matriz de covariância<br>\n",
    "$\\begin{bmatrix}\n",
    "[ 1.83862041 & -0.22786456 ]\\\\ \n",
    "[ -0.22786456 & 1.71533273 ]\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular o vetor de médias das colunas de Xtre\n",
    "# Substituir o comando abaixo pelo cálculo do vetor de médias\n",
    "# Dica: usar np.mean\n",
    "MU = np.zeros([1, 2])\n",
    "print('Vetor de médias')\n",
    "print(MU)\n",
    "\n",
    "\n",
    "# Calcular a matriz de covariancia\n",
    "# A função np.cov espera como argumento uma matriz\n",
    "# Nessa matriz, cada variável deve estar em uma linha\n",
    "# Portanto é necessário usar a transposta de Xtre (Xtre.T)\n",
    "# Dica Usar np.cov\n",
    "# Substituir o comando abaixo pelo cálculo da matriz de covariância\n",
    "# Dica: usa np.cov\n",
    "SIGMA = np.zeros([2,2])\n",
    "print('\\nMatriz de covarância')\n",
    "print(SIGMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 4 - Vizualizar aderência dos dados ao modelo\n",
    "* Visualizar o gráfico tridimensional da Gaussiana Multivariada\n",
    "* Visualizar as curvas de nível da distribuição normal multivariada junto com o gráfico de dispersão das variáeis (latência e throughput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vizualizar o gráfico tridimensional da Gaussiana Multivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a função multivariada\n",
    "nmv = multivariate_normal(MU, SIGMA)\n",
    "\n",
    "# Coordenadas X, Y e Z\n",
    "x = np.linspace(np.min(latencia)-1, np.max(latencia)+1, 100)\n",
    "y = np.linspace(np.min(throughput)-1, np.max(throughput)+1, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "pos = np.dstack((X, Y))\n",
    "Z = nmv.pdf(pos)\n",
    "\n",
    "# Criar os objetos figure e axes\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "# Rótulos dos eixos x, y, z\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "\n",
    "# Título do gráfico\n",
    "ax.set_title('Gaussiana Multivariada');\n",
    "\n",
    "# Plotagem\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, Y, Z, rstride=3, cstride=3, linewidth=1,\n",
    "                cmap='winter', edgecolor='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar curvas de nível e dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "contorno = ax.contour(X, Y, Z, 6,\n",
    "           levels=(0.000001,0.00001,0.0001,0.001,0.01,0.06),\n",
    "           linewidths=1.0)\n",
    "\n",
    "ax.autoscale(False)\n",
    "ax.scatter(latencia,throughput,zorder=1,s=3)\n",
    "\n",
    "ax.set_xlabel('Latência (ms)')\n",
    "ax.set_ylabel('Throughput (mb/s)')\n",
    "ax.set_title('Aderência dos dados ao modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 5: Ajustar o modelo\n",
    "No gráfico anterior podemos observar apenas quatro pontos fora da curva de contorno no nível 0.000001 (o nível mais externo).<br>\n",
    "\n",
    "O ajuste de modelo é um algoritmo que calcula o nível (limiar) da coordenada Z (valor da pmf) a partir do qual os dados são considerados como anomalias (outliers). O algoritmo de ajuste escolhe o limiar que faz as melhores previsões.<br>\n",
    "\n",
    "O algoritmo de ajuste do modelo utiliza os dados de validação. Os dados de validação precisam ser rotulados, isto é, para cada conjunto de valores das variáveis do modelo, precisamos da indicação (rótulo) se aquele conjunto de valores corresponde a uma anomalia (valor 1) ou não(valor 0).<br>\n",
    "\n",
    "A matriz Xval (caregada no Passo 1) tem os dados para validação de latência e throughput (colunas 1 e 2), enquanto que o vetor Yval que tem os valores rotulados correspondentes. Yval é um vetor de 0s e 1s sendo que 1 significa dados com anomaila e 0 dados sem anomalia.<br>\n",
    "\n",
    "#### Algoritmo de ajuste\n",
    "\n",
    "\n",
    "##### Selecionar limiar\n",
    "O algoritmo está implementado na função selecionarLimiar. Para escolher o melhor limiar a algoritmo utiliza a métrica F1. Consiste em um laço que varre todos os valores no vetor $Pval$ para escolher o valor que produz o maior valor resultado.\n",
    "\\===================================================================<br>\n",
    "\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* Algoritmo para determinar o valor do limiar \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n",
    "\\===================================================================\n",
    "* Recebe como argumento o vetor Pval e o vetor Yval\n",
    "* Transformar Yval em boleano e salvar e Real\n",
    "  * Real = Yval.astype(np.bool)\n",
    "* Inicia os valores das variáveis locais usadas no algoritmo\n",
    "  * melhorLimiar = 0\n",
    "  * melhorF1 = 0\n",
    "* Variar os valores de limiar de $min(Pval)$ a $max(Pval)$ com passo igual $(max(Pval) - min(Pval)) / 1000$\n",
    "* Para cada valor do limiar\n",
    "  * Calcular o vetor de previsões do modelo\n",
    "   * Prev = limiar < Pval\n",
    "   * Ao comparamos o valor do limiar como vetor Pval o resultado será um vetor de valores booleanos que satifazem a condição que é aolvo no vetor Prev\n",
    "  * Calcular a quantidade de verdadeiros positivos (vp)\n",
    "   * Calcular um vetor booleano de acordo com a seguinte expressão lógica:\n",
    "     * Real == anomalia E Previsto == anomalia\n",
    "     * Dica: np.logical_and((Prev == 1.0),(Yval == 1.0))\n",
    "    * Somar a quantidade de True e salvar em vp<br>\n",
    "     * Dica: vp = np.count_nonzero(np.logical_and((Prev == 1.0),(Yval == 1.0))) \n",
    "  * Calcular a quantidade de falsos positivos (fp)\n",
    "   * Calcular um vetor booleano de acordo com a seguinte expressão lógica:\n",
    "     * Real == anomalia E Previsto == não anomalia\n",
    "     * Dica: np.logical_and((Prev == 1.0),(Yval == 0.0))\n",
    "    * Somar a quantidade de True e salvar em fp<br>\n",
    "     * Dica: fp = np.count_nonzero(np.logical_and((Prev == 1.0),(Yval == 0.0))) \n",
    "  * Calcular a quantidade de falsos negativos (fn)\n",
    "   * Calcular um vetor booleano de acordo com a seguinte expressão lógica:\n",
    "     * Real == não anomalia E Previsto == anomalia\n",
    "     * Dica: np.logical_and((Prev == 0.0),(Yval == 1.0))\n",
    "    * Somar a quantidade de True e salvar em fp<br>\n",
    "     * Dica: fn = np.count_nonzero(np.logical_and((Prev == 0.0),(Yval == 1.0))) \n",
    "  * Calcular F1\n",
    "  * Se F1 > melhorF1\n",
    "    * melhorF1 = F1\n",
    "    * melhorLimiar = limiar\n",
    "\n",
    "\\==================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Completar o código da função slelecionarLimiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecionarLimiar(Pval, Yval):\n",
    "    # Iniciar os valores das variáveis locais\n",
    "    melhorLimiar = 0\n",
    "    melhorF1 = 0\n",
    "    F1 = 0\n",
    "    \n",
    "    passo = (np.max(Pval) - np.min(Pval)) / 1000\n",
    "    # print(np.arange(np.min(Pval), np.max(Pval), passo))\n",
    "    for limiar in np.arange(np.min(Pval), np.max(Pval), passo):\n",
    "        # Calcular o vetor de previsões\n",
    "        Prev = (Pval < limiar).astype(np.float64)\n",
    "\n",
    "        # Calcular os verdadeiros positivos\n",
    "        vp = np.count_nonzero(np.logical_and((Prev == 1),(Yval == 1)))\n",
    "\n",
    "        ###############################################################\n",
    "        # Substituir o comando abaixo para calcular os falsos positivos\n",
    "        fp = 0\n",
    "\n",
    "        ###############################################################\n",
    "        # Substituir o comando abaixo para calcular os falsos negativos\n",
    "        fn = 0\n",
    "        \n",
    "        if vp !=0:\n",
    "            # Calcular F1\n",
    "            prec = vp/(vp+fp)  # calcular prec\n",
    "            rec = vp/(vp+fn)   # calcular rec\n",
    "            F1 = (2*prec*rec) / (prec+rec)  # calcular de F1\n",
    "        \n",
    "        # Se o novo valor de F1 é melhor do que o melhor até agora\n",
    "        #Salva o valor atual de F1 e de epsilon em melhorF1 e melhorEpisilon\n",
    "        if F1 > melhorF1:\n",
    "            melhorF1 = F1\n",
    "            melhorLimiar = limiar\n",
    "            \n",
    "    return melhorF1, melhorLimiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparar dos dados\n",
    "Para selecionar o limiar de decisão utilizamos os dados de treinamento: matriz de dados das variáveis $Xval$ e vetor de rótulos $Yval$.<br><br>\n",
    "A função $selecionaLimiar$ recebe como argumento os valores de probabilidade das variáveis de validação ($Pval$) que são calculados pela Gaussiana Multivariada (com parâmetros $MU$ e $SIGMA$).<br><br>\n",
    "Realizar os seguintes passos: \n",
    "* Chamar a função Gaussiana Multivariada passando os dados de validação ($Xval$) como argumento armazenando o resultado array $Pval$\n",
    "* Chamar a função $selecionarLimiar$ passando como argumentos $Pval$ e $Yval$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pval = nmv.pdf(Xval)\n",
    "F1, limiar = selecionarLimiar(Pval,Yval)\n",
    "print(limiar)\n",
    "print(F1)\n",
    "print('Se o algoritmo estiver certo, o valor do limiar deve ser 9.036141e-05')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 6 - Visualizar as anomalias no conjunto de treinamento\n",
    "* Encontrar as anomalias no conjunto de treinamento\n",
    "* Plotar anomalias do conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Encontrar e as anomalias no conjunto de treinamento\n",
    "\n",
    "# Calcular a probabilidade de cada variável em Xtre\n",
    "p = nmv.pdf(Xtre)\n",
    "\n",
    "# As anomalias são os elementos cuja probabilidade é menor do que o limiar\n",
    "anomalias = Xtre[p < limiar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar anomalias do conjunto de treinamento\n",
    "fig, ax = plt.subplots()\n",
    "contorno = ax.contour(X, Y, Z, 6,\n",
    "           levels=(0.000001,0.00001,0.0001,0.001,0.01,0.06),\n",
    "           linewidths=1.0)\n",
    "\n",
    "ax.autoscale(False)\n",
    "ax.scatter(latencia,throughput,zorder=1,s=3)\n",
    "ax.scatter(anomalias[:,0],anomalias[:,1],zorder=2)\n",
    "\n",
    "ax.set_xlabel('Latência (ms)')\n",
    "ax.set_ylabel('Throughput (mb/s)')\n",
    "ax.set_title('Anomalias');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 - Dataset multidimensional\n",
    "\n",
    "Na Parte 2 vamos utilizar os arquivos DadosTreinamento2.csv, DadosValidacao2.csv e DadosTeste2.csv, que contêm dados de treinamento e validação e teste. Os arquivos com dados de validação e teste tambem incluem dados rotulados (Y) para uso em validação e teste.<br><br>\n",
    "\n",
    "Nos arquivos da Parte 2  foram coletadas 11 variáveis de desempenho dos servidores. Não é possível fazer as vizualizações que foram feitas na Parte 1, mas os algoritmos que foram implementados podem ser usados aqui, porque o tratamento é válido para matrizes de dados de quaisquer dimensões.\n",
    "\n",
    "* Passo 1 - Carregar dados\n",
    "* Passo 2 - Treinar o modelo\n",
    "* Passo 3 - Ajustar o modelo\n",
    "* Passo 4 - Testar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1 - Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo com dados de treinamento\n",
    "Xtre = np.loadtxt('DadosTreinamento2.csv', delimiter=',')\n",
    "print(Xtre.shape)\n",
    "\n",
    "# Leitura do arquivo com dados de validação\n",
    "XYval = np.loadtxt('DadosValidacao2.csv', delimiter=',')\n",
    "Xval = XYval[:,[0,1,2,3,4,5,6,7,8,9,10]]\n",
    "print(Xval.shape)\n",
    "Yval = XYval[:,11]\n",
    "print(Yval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 2 - Treinar o modelo\n",
    "* Calcular o vetor de médias\n",
    "* Calcular a matriz de covariância\n",
    "* Definir a função Gaussiana multivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular o vetor de médias das colunas de Xtre\n",
    "###############################################\n",
    "# Mesmo comando usado na parte 1\n",
    "# MU = ...\n",
    "\n",
    "# Calcular a matriz de covariancia\n",
    "################################################\n",
    "# Mesmo comado usado na parte 1\n",
    "# SIGMA = ....\n",
    "\n",
    "# Definir a função multivariada\n",
    "nmv = multivariate_normal(MU, SIGMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 3: Ajustar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pval = nmv.pdf(Xval)\n",
    "F1, limiar = selecionarLimiar(Pval,Yval)\n",
    "print(limiar)\n",
    "print(F1)\n",
    "print('O valor do limiar deve ser 1.824432e-18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 4: Testar o modelo\n",
    "Calcular as métricas F1 para os dados de teste correspondentes a anomalias.<br>\n",
    "* Carregar o arquivo DadosTeste2.csv\n",
    "* Calcular a métrica exatidão (accuracy)<br>\n",
    "$acc =\\frac{vp+vn}{vp+fp+vn+fn}$\n",
    "* Calcular a métrica precisão (precision)<br>\n",
    "$prec = \\frac{vp}{vp+fp}$\n",
    "* Calcular a métrica revocação (recall)<br>\n",
    "$rec = \\frac{vp}{vp+fn}$\n",
    "* Calcular a métrica F1<br>\n",
    "$F1 = \\frac{2\\cdot prec \\cdot rec}{prec+rec}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo com dados de teste\n",
    "XYtest = np.loadtxt('DadosTeste2.csv', delimiter=',')\n",
    "# Onze primeiras colunas contêm os dados das variáveis\n",
    "Xtest = XYtest[:,[0,1,2,3,4,5,6,7,8,9,10]]\n",
    "\n",
    "# Última coluna contém os rótulos\n",
    "Ytest = XYtest[:,11]\n",
    "# print(Ytest.shape)\n",
    "\n",
    "# Encontrar as anomalias no conjunto de teste\n",
    "Pval = nmv.pdf(Xtest)\n",
    "\n",
    "# Previsões do modelo\n",
    "Yprev = (Pval < limiar).astype(np.float64)\n",
    "\n",
    "# Verdadeiros positivos\n",
    "vp = np.count_nonzero(np.logical_and((Yprev == 1),(Ytest == 1)))\n",
    "\n",
    "#################################################################\n",
    "# Substituir o comando abaixo para calcular verdadeiros negativos\n",
    "vn = 0\n",
    "\n",
    "#################################################################\n",
    "# Substituir o comando abaixo para calcular falsos positivos\n",
    "fp = 0\n",
    "\n",
    "#################################################################\n",
    "# Substituir o comando abaixo para calcular falsos negativos\n",
    "fn = 0\n",
    "\n",
    "# Exatidão (accuracy)\n",
    "acc = (vp+vn)/(vp+vn+fp+fn)\n",
    "\n",
    "# Precisão (precision)\n",
    "prec = vp/(vp+fp)\n",
    "\n",
    "# Revocação (recall)\n",
    "rec = vp/(vp+fn)\n",
    "\n",
    "###################################################################\n",
    "# Substituir o comando abaixo para calcular F1\n",
    "F1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3 - TDE 02\n",
    "A Parte 2 só precisa ser resolvida no TDE 02."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular média ponderada das métricas de avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc = (vp+vn)/(vp+vn+fp+fn)\n",
    "\n",
    "# prec rec F1 para anomalias\n",
    "prec_1 = vp/(vp+fp)\n",
    "rec_1 = vp/(vp+fn)\n",
    "F1_1 = (2*prec_1*rec_1) / (prec_1+rec_1)\n",
    "\n",
    "# prec rec F1 para não anomalias\n",
    "prec_0 = vn/(vn+fn)\n",
    "rec_0 = vn/(vn+fp)\n",
    "F1_0 = (2*prec_0*rec_0) / (prec_0+rec_0)\n",
    "\n",
    "# prec rec F1 média ponderada\n",
    "support_0 = fp + vn\n",
    "support_1 = vp + fn\n",
    "prec_mp = (prec_0 * support_0 + prec_1 * support_1) / (support_0 + support_1)\n",
    "rec_mp = (rec_0 * support_0 + rec_1 * support_1) / (support_0 + support_1)\n",
    "F1_mp = (F1_0 * support_0 + F1_1 * support_1) / (support_0 + support_1)\n",
    "print(F1_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
